{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "answering-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib.pyplot import *\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "residential-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Load train set and test set and normalize the images in range [-1,1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#50000 images training\n",
    "trainset = torchvision.datasets.CIFAR10(root='./dataCaps', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#We load 4 samples per batchreduce the traininset to 12500\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)#batch size changed from 4 to 100\n",
    "\n",
    "#print(len(trainset))\n",
    "#10000 images test\n",
    "testset = torchvision.datasets.CIFAR10(root='./dataCaps', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)#batch size changed from 4 to 100\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "operating-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=256, kernel_size=9):\n",
    "        \n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=1\n",
    "                             )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0) \n",
    "                          for _ in range(num_capsules)])\n",
    "    def forward(self, x):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=4) #it was 4 here\n",
    "        u = u.view(x.size(0), 32 * 8 * 8, -1)#output = output.view(x.size(0), self.num_capsules*(self.gridsize)*(self.gridsize), -1)\n",
    "        return self.squash(u)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applicable-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=10, num_routes=32 * 8 * 8, in_channels=8, out_channels=16):\n",
    "        super(DigitCaps, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        \n",
    "        u_hat = torch.matmul(W, x)\n",
    "        \n",
    "\n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
    "        #print('b_ij:',b_ij.size())\n",
    "        #if USE_CUDA:\n",
    "         #   b_ij = b_ij.cuda()\n",
    "\n",
    "        num_iterations = 3\n",
    "        for iteration in range(num_iterations):\n",
    "            c_ij = F.softmax(b_ij, dim=2)\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            v_j = self.squash(s_j)\n",
    "            \n",
    "            if iteration < num_iterations - 1:\n",
    "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "                #print('u_hat.transpose(3, 4):',u_hat.transpose(3, 4).size(),'torch.cat([v_j] * self.num_routes, dim=1):',torch.cat([v_j] * self.num_routes, dim=1).size(),'aij:',a_ij.squeeze(4).mean(dim=0, keepdim=True).size())\n",
    "                aij = a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "                b_ij = b_ij + aij\n",
    "                #print('bij:',b_ij.size())\n",
    "\n",
    "        return v_j.squeeze(1)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "american-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "#num capsule=10, capsule_size=16, imsize=32, img_channel=3        \n",
    "        self.reconstraction_layers = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512), #nn.Linear(capsule_size*num_capsules, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 3072), #nn.Linear(1024, imsize*imsize*img_channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, data):\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        classes = F.softmax(classes)\n",
    "        \n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        masked = Variable(torch.sparse.torch.eye(10)) #Variable(torch.sparse.torch.eye(num_capsules))\n",
    "        #if USE_CUDA:\n",
    "        #    masked = masked.cuda()\n",
    "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
    "        \n",
    "        reconstructions = self.reconstraction_layers((x * masked[:, :, None, None]).view(x.size(0), -1))\n",
    "        reconstructions = reconstructions.view(-1, 3, 32, 32) #reconstructions.view(-1, 1, 28, 28)\n",
    "        \n",
    "        return reconstructions, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.conv_layer = ConvLayer()\n",
    "        self.primary_capsules = PrimaryCaps()\n",
    "        self.digit_capsules = DigitCaps()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
    "        reconstructions, masked = self.decoder(output, data)\n",
    "        return output, reconstructions, masked\n",
    "    \n",
    "    def loss(self, data, x, target, reconstructions):\n",
    "        #return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
    "        marg_loss = self.margin_loss(x, target)\n",
    "        rec_loss = self.reconstruction_loss(data, reconstructions)\n",
    "        total_loss = (marg_loss + 0.0005 * rec_loss).mean()\n",
    "        return total_loss, rec_loss.mean(), marg_loss.mean()\n",
    "    \n",
    "    def margin_loss(self, x, labels, size_average=True):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        v_c = torch.norm((x), dim=2, keepdim=True)\n",
    "        #print ((functional.relu(0.9 - v_c)).size())\n",
    "        left = functional.relu(0.9 - v_c).view(batch_size, -1) **2\n",
    "        right = functional.relu(v_c - 0.1).view(batch_size, -1) **2\n",
    "        #print('left:',left.size(),'right:',right.size(), 'labels:',labels.size())\n",
    "        #print((labels.t()).size())\n",
    "        #print('1st:',(labels*left.t()).size())\n",
    "        #print('2nd:',((torch.ones(1,100) - labels.t()) * right.t()).size())\n",
    "        \n",
    "        loss = labels * left.t() + 0.5 * (1.0 - labels) * right.t()\n",
    "        \n",
    "        loss = loss.sum(dim=1)#.mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def reconstruction_loss(self, data, reconstructions):\n",
    "        batch_size = reconstructions.size(0)\n",
    "        \n",
    "        reconstructions = reconstructions.view(batch_size, -1)\n",
    "        #print('data',data[0])\n",
    "        data = data.view(batch_size, -1)#here it was data[0]\n",
    "        #print('rec',(reconstructions).size(),'data',data.size())\n",
    "        loss = nn.MSELoss()(reconstructions,data)\n",
    "        #self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ongoing-negative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ed7bfe86d42e>:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  classes = F.softmax(classes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: -107.021\n",
      "[1,  4000] loss: -106.686\n",
      "[1,  6000] loss: -106.097\n",
      "[1,  8000] loss: -107.131\n",
      "[1, 10000] loss: -106.051\n",
      "[1, 12000] loss: -105.869\n",
      "[2,  2000] loss: -105.383\n",
      "[2,  4000] loss: -106.398\n",
      "[2,  6000] loss: -107.207\n",
      "[2,  8000] loss: -107.876\n",
      "[2, 10000] loss: -106.029\n",
      "[2, 12000] loss: -105.660\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training network over 2 epochs\n",
    "capsule_net = CapsNet()\n",
    "#Define Loss function and optimizer\n",
    "# Loss Function: cross entropy\n",
    "# Optimizer: SGD\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Adam(capsule_net.parameters())\n",
    "optimizer = optim.SGD(capsule_net.parameters(), lr=0.001, momentum=0.9)\n",
    "epochs=2\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "#print('inputs',inputs.size(),'labels',labels.size())\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, reconstructions, masked = capsule_net(inputs)\n",
    "        #print('inputs',inputs.size(),'labels',labels,'outpu',outputs.size(), 'rec', reconstructions.size())\n",
    "        #print(outputs)\n",
    "        loss, rec_loss, marginal_loss = capsule_net.loss(inputs, outputs, labels, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print('epoch:',epoch,'batch:',i)\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unable-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training saving\n",
    "PATH = './cifar_CapsNet_SGD_2epochs.pth'\n",
    "torch.save(capsule_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "artistic-pavilion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-ed7bfe86d42e>:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  classes = F.softmax(classes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 40 %\n",
      "-106.43563184500378\n"
     ]
    }
   ],
   "source": [
    "#dataiter = iter(testloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "PATH = './cifar_CapsNet_SGD_2epochs.pth'\n",
    "#Load previously net from choosen training\n",
    "capsule_net = CapsNet()\n",
    "capsule_net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "capsule_net.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, datas in enumerate(testloader, 0):\n",
    "    inputs, labels = datas\n",
    "    #print('images',inputs.size(),'labels',labels.size())\n",
    "    target = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        #dataCaps, target = Variable(dataCaps), Variable(target)\n",
    "\n",
    "        \n",
    "    output, reconstructions, masked = capsule_net(inputs)\n",
    "    #print ('outputs',output.size())\n",
    "    loss, rec_loss, marg_loss = capsule_net.loss(inputs, output, labels, reconstructions)\n",
    "    test_loss += loss.item()\n",
    "    outputs= torch.sum(torch.abs(output), 2)\n",
    "    _, predicted = torch.max(outputs.data, 1) #torch.max(input, dim) return maximum value of all element from input tensor in the given dim\n",
    "    total += labels.size(0) #count the number of labels with right shape\n",
    "    correct += (predicted == labels).sum().item() #count the number of right labels \n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))    \n",
    "    \n",
    "print (test_loss / len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-regulation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
