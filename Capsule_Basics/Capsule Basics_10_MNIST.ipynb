{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2d66b3576f429397ae6d6e6ee0c12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ab812871524d9f832b064ccbb329a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2d4aa6f26143938083c08320ee6ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21af4a4f583842bb82fe4e4d7d1508de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentinibars/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-7w1l4mea/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Load train set and test set and normalize the images in range [-1,1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(( 0.1307,), ( 0.3081,))])\n",
    "\n",
    "#50000 images training\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#We load 4 samples per batch reduce the traininset to 12500\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "#print(len(trainset))\n",
    "#10000 images test\n",
    "testset = torchvision.datasets.MNIST(root='./mnist', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "#We load 4 samples per batchreduce the traininset to 2500\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "classes = list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
    "        \n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=1\n",
    "                             )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #We want to transform 32x32x3 in 20x20x256 \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=32, in_channels=256, out_channels=8, kernel_size=9):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=num_capsules, kernel_size=kernel_size, stride=2, padding=0) \n",
    "                          for _ in range(out_channels)])\n",
    "    def forward(self, x):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=4) \n",
    "        u = u.view(x.size(0), 32 * 6 * 6, -1)\n",
    "        #change shape of tensor to 32 capsules of 8x6x6  gridsize=6\n",
    "        return self.squash(u)\n",
    "    \n",
    "    #Squash function maintaining the direction of the vector (use instead of RELU activation fct in CNN)\n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm)+ 1e-8)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=10, num_routes=32 * 6 * 6, in_channels=8, out_channels=16):\n",
    "        super(DigitCaps, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        \n",
    "        self.W = nn.Parameter(0.01*torch.randn(1, num_capsules, num_routes, out_channels, in_channels))#0.01 added from danielhavir\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        x = x.unsqueeze(4)\n",
    "        \n",
    "        \n",
    "        u_hat = torch.matmul(self.W, x) #matmul = matrix multiplication\n",
    "        \n",
    "        u_hat = u_hat.squeeze(-1)\n",
    "        temp_u_hat = u_hat.detach()\n",
    "        \n",
    "        b_ij = torch.zeros(batch_size,  self.num_capsules, self.num_routes,1)\n",
    "        num_iterations = 3 #number of routing\n",
    "\n",
    "        #this is the routing algorithm\n",
    "        for iteration in range(num_iterations-1):\n",
    "            #compute coupling coefficient, Conceptually: measure how likely capsule i may activate capsule j\n",
    "            c_ij = F.softmax(b_ij, dim=1)\n",
    "            \n",
    "            s_j = (c_ij * temp_u_hat).sum(dim=2)\n",
    "            \n",
    "            v_j = self.squash(s_j)\n",
    "            delta = torch.matmul(temp_u_hat, v_j.unsqueeze(-1))\n",
    "            b_ij = b_ij + delta\n",
    "        \n",
    "        c_ij = F.softmax(b_ij, dim=2)\n",
    "        s_j = (c_ij * u_hat).sum(dim=2)\n",
    "        \n",
    "        v_j = self.squash(s_j)\n",
    "        \n",
    "        return v_j\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module): #difference between decoder and reconstruction ????\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "#num capsule=10, capsule_size=16, imsize=32, img_channel=3        \n",
    "        self.reconstraction_layers = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512), #nn.Linear(capsule_size*num_capsules, 512),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            #nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 784), #nn.Linear(1024, imsize*imsize*img_channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, output):\n",
    "        batch_size = output.size(0)\n",
    "        classes = torch.norm(output, dim=2)\n",
    "        \n",
    "        \n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "\n",
    "        masked = torch.eye(10)\n",
    "    \n",
    "        masked = masked.index_select(dim=0, index=max_length_indices).unsqueeze(2)\n",
    "        reconstructions = self.reconstraction_layers( (output*masked).view(batch_size, -1) )\n",
    "        reconstructions = reconstructions.view(-1, 1, 28, 28)\n",
    "        return reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.conv_layer = ConvLayer()\n",
    "        self.primary_capsules = PrimaryCaps()\n",
    "        self.digit_capsules = DigitCaps()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print ('original:',x.size()) #size=4,3,32,32\n",
    "        output = self.conv_layer(x)\n",
    "        #print(\"conv:\",output.size()) #size=4,256,24,24\n",
    "        output = self.primary_capsules(output)\n",
    "        #print(\"prim:\",output.size()) #size=4,2048,8\n",
    "        output = self.digit_capsules(output)\n",
    "        #print(\"digit:\",output.size()) #size=4,10,16\n",
    "        preds = torch.norm(output, dim=-1)\n",
    "        reconstructions = self.decoder(output)\n",
    "        return preds, reconstructions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, size_average=False, loss_lambda=0.5):\n",
    "        super(MarginLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "        self.m_plus = 0.9\n",
    "        self.m_minus = 0.1\n",
    "        self.loss_lambda = loss_lambda\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        \n",
    "        left=F.relu(self.m_plus - inputs)**2\n",
    "        right=F.relu(inputs - self.m_minus)**2\n",
    "        L_k = labels * left + self.loss_lambda * (1 - labels) * right\n",
    "        L_k = L_k.sum(dim=1)\n",
    "        if self.size_average:\n",
    "            return L_k.mean()\n",
    "        else:\n",
    "            return L_k.sum()\n",
    "\n",
    "class CapsuleLoss(nn.Module):\n",
    "    def __init__(self, loss_lambda=0.5, recon_loss_scale=5e-4, size_average=False):\n",
    "\n",
    "        super(CapsuleLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "        self.margin_loss = MarginLoss(size_average=size_average, loss_lambda=loss_lambda)\n",
    "        self.reconstruction_loss = nn.MSELoss(size_average=size_average)\n",
    "        self.recon_loss_scale = recon_loss_scale\n",
    "\n",
    "    def forward(self, inputs, labels, images, reconstructions):\n",
    "        margin_loss = self.margin_loss(inputs, labels)\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
    "        caps_loss = (margin_loss + self.recon_loss_scale * reconstruction_loss)\n",
    "\n",
    "        return caps_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 2.896, accuracy: 54.450\n",
      "[1,  1000] loss: 1.489, accuracy: 92.300\n",
      "[1,  1500] loss: 1.336, accuracy: 94.650\n",
      "[1,  2000] loss: 1.271, accuracy: 95.650\n",
      "[1,  2500] loss: 1.263, accuracy: 96.350\n",
      "[1,  3000] loss: 1.318, accuracy: 95.300\n",
      "[1,  3500] loss: 1.334, accuracy: 95.350\n",
      "[1,  4000] loss: 1.402, accuracy: 93.350\n",
      "[1,  4500] loss: 1.347, accuracy: 94.000\n",
      "[1,  5000] loss: 1.271, accuracy: 96.150\n",
      "[1,  5500] loss: 1.258, accuracy: 96.300\n",
      "[1,  6000] loss: 1.303, accuracy: 95.350\n",
      "[1,  6500] loss: 1.354, accuracy: 95.150\n",
      "[1,  7000] loss: 1.264, accuracy: 96.100\n",
      "[1,  7500] loss: 1.248, accuracy: 96.450\n",
      "[1,  8000] loss: 1.267, accuracy: 95.950\n",
      "[1,  8500] loss: 1.291, accuracy: 95.700\n",
      "[1,  9000] loss: 1.272, accuracy: 96.050\n",
      "[1,  9500] loss: 1.244, accuracy: 96.900\n",
      "[1, 10000] loss: 1.235, accuracy: 97.050\n",
      "[1, 10500] loss: 1.234, accuracy: 97.400\n",
      "[1, 11000] loss: 1.261, accuracy: 96.550\n",
      "[1, 11500] loss: 1.222, accuracy: 97.100\n",
      "[1, 12000] loss: 1.221, accuracy: 96.750\n",
      "[1, 12500] loss: 1.190, accuracy: 97.950\n",
      "[1, 13000] loss: 1.213, accuracy: 96.850\n",
      "[1, 13500] loss: 1.245, accuracy: 96.700\n",
      "[1, 14000] loss: 1.186, accuracy: 98.300\n",
      "[1, 14500] loss: 1.238, accuracy: 97.450\n",
      "[1, 15000] loss: 1.228, accuracy: 96.850\n",
      "[2,   500] loss: 1.203, accuracy: 97.700\n",
      "[2,  1000] loss: 1.197, accuracy: 98.100\n",
      "[2,  1500] loss: 1.197, accuracy: 97.750\n",
      "[2,  2000] loss: 1.191, accuracy: 97.950\n",
      "[2,  2500] loss: 1.190, accuracy: 97.700\n",
      "[2,  3000] loss: 1.163, accuracy: 98.650\n",
      "[2,  3500] loss: 1.170, accuracy: 98.300\n",
      "[2,  4000] loss: 1.169, accuracy: 98.550\n",
      "[2,  4500] loss: 1.158, accuracy: 98.700\n",
      "[2,  5000] loss: 1.161, accuracy: 98.200\n",
      "[2,  5500] loss: 1.156, accuracy: 98.800\n",
      "[2,  6000] loss: 1.165, accuracy: 98.650\n",
      "[2,  6500] loss: 1.158, accuracy: 98.250\n",
      "[2,  7000] loss: 1.144, accuracy: 98.550\n",
      "[2,  7500] loss: 1.161, accuracy: 98.000\n",
      "[2,  8000] loss: 1.158, accuracy: 98.200\n",
      "[2,  8500] loss: 1.131, accuracy: 98.650\n",
      "[2,  9000] loss: 1.139, accuracy: 98.450\n",
      "[2,  9500] loss: 1.126, accuracy: 98.600\n",
      "[2, 10000] loss: 1.131, accuracy: 98.800\n",
      "[2, 10500] loss: 1.123, accuracy: 98.750\n",
      "[2, 11000] loss: 1.140, accuracy: 98.200\n",
      "[2, 11500] loss: 1.147, accuracy: 98.600\n",
      "[2, 12000] loss: 1.108, accuracy: 98.850\n",
      "[2, 12500] loss: 1.126, accuracy: 98.650\n",
      "[2, 13000] loss: 1.122, accuracy: 98.500\n",
      "[2, 13500] loss: 1.114, accuracy: 99.100\n",
      "[2, 14000] loss: 1.120, accuracy: 98.750\n",
      "[2, 14500] loss: 1.108, accuracy: 98.600\n",
      "[2, 15000] loss: 1.104, accuracy: 98.800\n",
      "[3,   500] loss: 1.084, accuracy: 99.400\n",
      "[3,  1000] loss: 1.099, accuracy: 99.050\n",
      "[3,  1500] loss: 1.079, accuracy: 99.300\n",
      "[3,  2000] loss: 1.092, accuracy: 98.800\n",
      "[3,  2500] loss: 1.089, accuracy: 99.000\n",
      "[3,  3000] loss: 1.072, accuracy: 99.150\n",
      "[3,  3500] loss: 1.096, accuracy: 98.850\n",
      "[3,  4000] loss: 1.082, accuracy: 98.900\n",
      "[3,  4500] loss: 1.095, accuracy: 99.000\n",
      "[3,  5000] loss: 1.098, accuracy: 98.700\n",
      "[3,  5500] loss: 1.092, accuracy: 99.100\n",
      "[3,  6000] loss: 1.090, accuracy: 99.200\n",
      "[3,  6500] loss: 1.089, accuracy: 99.150\n",
      "[3,  7000] loss: 1.084, accuracy: 99.050\n",
      "[3,  7500] loss: 1.088, accuracy: 99.100\n",
      "[3,  8000] loss: 1.095, accuracy: 99.350\n",
      "[3,  8500] loss: 1.083, accuracy: 99.150\n",
      "[3,  9000] loss: 1.076, accuracy: 99.000\n",
      "[3,  9500] loss: 1.091, accuracy: 98.900\n",
      "[3, 10000] loss: 1.086, accuracy: 98.800\n",
      "[3, 10500] loss: 1.076, accuracy: 98.900\n",
      "[3, 11000] loss: 1.096, accuracy: 98.750\n",
      "[3, 11500] loss: 1.100, accuracy: 98.800\n",
      "[3, 12000] loss: 1.074, accuracy: 98.900\n",
      "[3, 12500] loss: 1.081, accuracy: 98.850\n",
      "[3, 13000] loss: 1.087, accuracy: 98.500\n",
      "[3, 13500] loss: 1.069, accuracy: 99.150\n",
      "[3, 14000] loss: 1.086, accuracy: 98.700\n",
      "[3, 14500] loss: 1.076, accuracy: 99.250\n",
      "[3, 15000] loss: 1.069, accuracy: 98.850\n",
      "[4,   500] loss: 1.070, accuracy: 99.300\n",
      "[4,  1000] loss: 1.058, accuracy: 99.400\n",
      "[4,  1500] loss: 1.051, accuracy: 99.650\n",
      "[4,  2000] loss: 1.059, accuracy: 99.350\n",
      "[4,  2500] loss: 1.070, accuracy: 99.350\n",
      "[4,  3000] loss: 1.064, accuracy: 98.950\n",
      "[4,  3500] loss: 1.066, accuracy: 98.900\n",
      "[4,  4000] loss: 1.055, accuracy: 99.400\n",
      "[4,  4500] loss: 1.050, accuracy: 99.350\n",
      "[4,  5000] loss: 1.038, accuracy: 99.250\n",
      "[4,  5500] loss: 1.037, accuracy: 99.350\n",
      "[4,  6000] loss: 1.050, accuracy: 98.900\n",
      "[4,  6500] loss: 1.038, accuracy: 99.400\n",
      "[4,  7000] loss: 1.025, accuracy: 99.350\n",
      "[4,  7500] loss: 1.043, accuracy: 98.950\n",
      "[4,  8000] loss: 1.034, accuracy: 99.150\n",
      "[4,  8500] loss: 1.036, accuracy: 99.100\n",
      "[4,  9000] loss: 1.031, accuracy: 99.250\n",
      "[4,  9500] loss: 1.023, accuracy: 99.350\n",
      "[4, 10000] loss: 1.029, accuracy: 99.250\n",
      "[4, 10500] loss: 1.034, accuracy: 99.050\n",
      "[4, 11000] loss: 1.032, accuracy: 99.150\n",
      "[4, 11500] loss: 1.035, accuracy: 99.100\n",
      "[4, 12000] loss: 1.023, accuracy: 99.450\n",
      "[4, 12500] loss: 1.013, accuracy: 99.300\n",
      "[4, 13000] loss: 1.041, accuracy: 98.800\n",
      "[4, 13500] loss: 1.011, accuracy: 99.300\n",
      "[4, 14000] loss: 1.013, accuracy: 99.150\n",
      "[4, 14500] loss: 1.012, accuracy: 99.150\n",
      "[4, 15000] loss: 1.017, accuracy: 99.500\n",
      "[5,   500] loss: 1.007, accuracy: 99.450\n",
      "[5,  1000] loss: 1.003, accuracy: 99.600\n",
      "[5,  1500] loss: 1.000, accuracy: 99.450\n",
      "[5,  2000] loss: 1.017, accuracy: 99.400\n",
      "[5,  2500] loss: 1.008, accuracy: 99.550\n",
      "[5,  3000] loss: 1.019, accuracy: 99.400\n",
      "[5,  3500] loss: 1.001, accuracy: 99.400\n",
      "[5,  4000] loss: 0.994, accuracy: 99.600\n",
      "[5,  4500] loss: 1.003, accuracy: 99.500\n",
      "[5,  5000] loss: 1.000, accuracy: 99.500\n",
      "[5,  5500] loss: 1.007, accuracy: 99.750\n",
      "[5,  6000] loss: 0.992, accuracy: 99.600\n",
      "[5,  6500] loss: 1.001, accuracy: 99.400\n",
      "[5,  7000] loss: 0.994, accuracy: 99.700\n",
      "[5,  7500] loss: 1.006, accuracy: 99.300\n",
      "[5,  8000] loss: 1.014, accuracy: 99.150\n",
      "[5,  8500] loss: 1.017, accuracy: 98.950\n",
      "[5,  9000] loss: 1.013, accuracy: 99.450\n",
      "[5,  9500] loss: 1.009, accuracy: 99.600\n",
      "[5, 10000] loss: 1.008, accuracy: 99.250\n",
      "[5, 10500] loss: 0.995, accuracy: 99.500\n",
      "[5, 11000] loss: 1.015, accuracy: 99.200\n",
      "[5, 11500] loss: 1.005, accuracy: 99.100\n",
      "[5, 12000] loss: 0.990, accuracy: 99.500\n",
      "[5, 12500] loss: 1.005, accuracy: 99.300\n",
      "[5, 13000] loss: 1.007, accuracy: 99.400\n",
      "[5, 13500] loss: 0.991, accuracy: 99.450\n",
      "[5, 14000] loss: 0.994, accuracy: 99.600\n",
      "[5, 14500] loss: 1.007, accuracy: 99.400\n",
      "[5, 15000] loss: 1.013, accuracy: 99.100\n",
      "[6,   500] loss: 0.991, accuracy: 99.350\n",
      "[6,  1000] loss: 0.984, accuracy: 99.850\n",
      "[6,  1500] loss: 0.989, accuracy: 99.650\n",
      "[6,  2000] loss: 0.988, accuracy: 99.400\n",
      "[6,  2500] loss: 0.995, accuracy: 99.400\n",
      "[6,  3000] loss: 0.989, accuracy: 99.550\n",
      "[6,  3500] loss: 0.998, accuracy: 99.600\n",
      "[6,  4000] loss: 1.002, accuracy: 99.550\n",
      "[6,  4500] loss: 0.997, accuracy: 99.400\n",
      "[6,  5000] loss: 0.983, accuracy: 99.550\n",
      "[6,  5500] loss: 0.992, accuracy: 99.600\n",
      "[6,  6000] loss: 0.991, accuracy: 99.550\n",
      "[6,  6500] loss: 1.004, accuracy: 99.400\n",
      "[6,  7000] loss: 0.988, accuracy: 99.550\n",
      "[6,  7500] loss: 0.974, accuracy: 99.850\n",
      "[6,  8000] loss: 0.982, accuracy: 99.600\n",
      "[6,  8500] loss: 0.996, accuracy: 99.500\n",
      "[6,  9000] loss: 0.983, accuracy: 99.400\n",
      "[6,  9500] loss: 0.982, accuracy: 99.800\n",
      "[6, 10000] loss: 0.988, accuracy: 99.500\n",
      "[6, 10500] loss: 0.992, accuracy: 99.600\n",
      "[6, 11000] loss: 0.989, accuracy: 99.350\n",
      "[6, 11500] loss: 0.985, accuracy: 99.400\n",
      "[6, 12000] loss: 0.979, accuracy: 99.350\n",
      "[6, 12500] loss: 0.978, accuracy: 99.550\n",
      "[6, 13000] loss: 0.975, accuracy: 99.600\n",
      "[6, 13500] loss: 0.973, accuracy: 99.500\n",
      "[6, 14000] loss: 0.993, accuracy: 99.450\n",
      "[6, 14500] loss: 0.966, accuracy: 99.700\n",
      "[6, 15000] loss: 0.986, accuracy: 99.500\n",
      "[7,   500] loss: 0.964, accuracy: 99.600\n",
      "[7,  1000] loss: 0.966, accuracy: 99.900\n",
      "[7,  1500] loss: 0.975, accuracy: 99.850\n",
      "[7,  2000] loss: 0.971, accuracy: 99.550\n",
      "[7,  2500] loss: 0.981, accuracy: 99.300\n",
      "[7,  3000] loss: 0.967, accuracy: 99.550\n",
      "[7,  3500] loss: 0.968, accuracy: 99.550\n",
      "[7,  4000] loss: 0.969, accuracy: 99.600\n",
      "[7,  4500] loss: 0.986, accuracy: 99.700\n",
      "[7,  5000] loss: 0.961, accuracy: 99.650\n",
      "[7,  5500] loss: 0.968, accuracy: 99.650\n",
      "[7,  6000] loss: 0.960, accuracy: 99.700\n",
      "[7,  6500] loss: 0.957, accuracy: 99.650\n",
      "[7,  7000] loss: 0.967, accuracy: 99.450\n",
      "[7,  7500] loss: 0.970, accuracy: 99.550\n",
      "[7,  8000] loss: 0.953, accuracy: 99.700\n",
      "[7,  8500] loss: 0.962, accuracy: 99.650\n",
      "[7,  9000] loss: 0.965, accuracy: 99.650\n",
      "[7,  9500] loss: 0.968, accuracy: 99.700\n",
      "[7, 10000] loss: 0.956, accuracy: 99.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 10500] loss: 0.961, accuracy: 99.500\n",
      "[7, 11000] loss: 0.970, accuracy: 99.350\n",
      "[7, 11500] loss: 0.966, accuracy: 99.650\n",
      "[7, 12000] loss: 0.960, accuracy: 99.700\n",
      "[7, 12500] loss: 0.967, accuracy: 99.450\n",
      "[7, 13000] loss: 0.966, accuracy: 99.400\n",
      "[7, 13500] loss: 0.977, accuracy: 99.300\n",
      "[7, 14000] loss: 0.963, accuracy: 99.700\n",
      "[7, 14500] loss: 0.958, accuracy: 99.600\n",
      "[7, 15000] loss: 0.961, accuracy: 99.500\n",
      "[8,   500] loss: 0.955, accuracy: 99.550\n",
      "[8,  1000] loss: 0.949, accuracy: 99.750\n",
      "[8,  1500] loss: 0.952, accuracy: 99.700\n",
      "[8,  2000] loss: 0.965, accuracy: 99.650\n",
      "[8,  2500] loss: 0.960, accuracy: 99.750\n",
      "[8,  3000] loss: 0.953, accuracy: 99.850\n",
      "[8,  3500] loss: 0.928, accuracy: 99.800\n",
      "[8,  4000] loss: 0.953, accuracy: 99.650\n",
      "[8,  4500] loss: 0.947, accuracy: 99.650\n",
      "[8,  5000] loss: 0.951, accuracy: 99.750\n",
      "[8,  5500] loss: 0.953, accuracy: 99.650\n",
      "[8,  6000] loss: 0.948, accuracy: 99.900\n",
      "[8,  6500] loss: 0.944, accuracy: 99.850\n",
      "[8,  7000] loss: 0.949, accuracy: 99.550\n",
      "[8,  7500] loss: 0.948, accuracy: 99.750\n",
      "[8,  8000] loss: 0.953, accuracy: 99.600\n",
      "[8,  8500] loss: 0.941, accuracy: 99.750\n",
      "[8,  9000] loss: 0.957, accuracy: 99.750\n",
      "[8,  9500] loss: 0.943, accuracy: 99.700\n",
      "[8, 10000] loss: 0.945, accuracy: 99.700\n",
      "[8, 10500] loss: 0.949, accuracy: 99.650\n",
      "[8, 11000] loss: 0.941, accuracy: 99.450\n",
      "[8, 11500] loss: 0.941, accuracy: 99.550\n",
      "[8, 12000] loss: 0.947, accuracy: 99.550\n",
      "[8, 12500] loss: 0.940, accuracy: 99.700\n",
      "[8, 13000] loss: 0.952, accuracy: 99.600\n",
      "[8, 13500] loss: 0.938, accuracy: 99.700\n",
      "[8, 14000] loss: 0.952, accuracy: 99.450\n",
      "[8, 14500] loss: 0.942, accuracy: 99.550\n",
      "[8, 15000] loss: 0.951, accuracy: 99.400\n",
      "[9,   500] loss: 0.952, accuracy: 99.450\n",
      "[9,  1000] loss: 0.924, accuracy: 99.950\n",
      "[9,  1500] loss: 0.935, accuracy: 99.650\n",
      "[9,  2000] loss: 0.952, accuracy: 99.800\n",
      "[9,  2500] loss: 0.927, accuracy: 99.750\n",
      "[9,  3000] loss: 0.937, accuracy: 99.850\n",
      "[9,  3500] loss: 0.938, accuracy: 99.550\n",
      "[9,  4000] loss: 0.929, accuracy: 100.000\n",
      "[9,  4500] loss: 0.937, accuracy: 99.700\n",
      "[9,  5000] loss: 0.935, accuracy: 99.600\n",
      "[9,  5500] loss: 0.935, accuracy: 99.500\n",
      "[9,  6000] loss: 0.937, accuracy: 99.700\n",
      "[9,  6500] loss: 0.932, accuracy: 99.900\n",
      "[9,  7000] loss: 0.936, accuracy: 99.750\n",
      "[9,  7500] loss: 0.938, accuracy: 99.600\n",
      "[9,  8000] loss: 0.929, accuracy: 99.850\n",
      "[9,  8500] loss: 0.935, accuracy: 99.500\n",
      "[9,  9000] loss: 0.931, accuracy: 99.900\n",
      "[9,  9500] loss: 0.922, accuracy: 99.900\n",
      "[9, 10000] loss: 0.934, accuracy: 99.700\n",
      "[9, 10500] loss: 0.914, accuracy: 99.700\n",
      "[9, 11000] loss: 0.942, accuracy: 99.800\n",
      "[9, 11500] loss: 0.929, accuracy: 99.650\n",
      "[9, 12000] loss: 0.932, accuracy: 99.550\n",
      "[9, 12500] loss: 0.944, accuracy: 99.500\n",
      "[9, 13000] loss: 0.942, accuracy: 99.850\n",
      "[9, 13500] loss: 0.924, accuracy: 99.850\n",
      "[9, 14000] loss: 0.929, accuracy: 99.800\n",
      "[9, 14500] loss: 0.935, accuracy: 99.400\n",
      "[9, 15000] loss: 0.927, accuracy: 99.700\n",
      "[10,   500] loss: 0.930, accuracy: 99.800\n",
      "[10,  1000] loss: 0.919, accuracy: 99.900\n",
      "[10,  1500] loss: 0.921, accuracy: 99.700\n",
      "[10,  2000] loss: 0.921, accuracy: 99.700\n",
      "[10,  2500] loss: 0.919, accuracy: 99.900\n",
      "[10,  3000] loss: 0.933, accuracy: 99.750\n",
      "[10,  3500] loss: 0.932, accuracy: 99.800\n",
      "[10,  4000] loss: 0.926, accuracy: 99.900\n",
      "[10,  4500] loss: 0.929, accuracy: 99.850\n",
      "[10,  5000] loss: 0.940, accuracy: 99.700\n",
      "[10,  5500] loss: 0.925, accuracy: 99.750\n",
      "[10,  6000] loss: 0.922, accuracy: 99.600\n",
      "[10,  6500] loss: 0.928, accuracy: 99.700\n",
      "[10,  7000] loss: 0.928, accuracy: 99.450\n",
      "[10,  7500] loss: 0.925, accuracy: 99.650\n",
      "[10,  8000] loss: 0.922, accuracy: 99.900\n",
      "[10,  8500] loss: 0.933, accuracy: 99.750\n",
      "[10,  9000] loss: 0.916, accuracy: 99.800\n",
      "[10,  9500] loss: 0.922, accuracy: 99.450\n",
      "[10, 10000] loss: 0.923, accuracy: 99.750\n",
      "[10, 10500] loss: 0.924, accuracy: 99.650\n",
      "[10, 11000] loss: 0.926, accuracy: 99.700\n",
      "[10, 11500] loss: 0.914, accuracy: 99.650\n",
      "[10, 12000] loss: 0.929, accuracy: 99.550\n",
      "[10, 12500] loss: 0.916, accuracy: 99.850\n",
      "[10, 13000] loss: 0.917, accuracy: 99.800\n",
      "[10, 13500] loss: 0.913, accuracy: 99.750\n",
      "[10, 14000] loss: 0.915, accuracy: 99.800\n",
      "[10, 14500] loss: 0.916, accuracy: 99.600\n",
      "[10, 15000] loss: 0.927, accuracy: 99.450\n",
      "[11,   500] loss: 0.921, accuracy: 99.800\n",
      "[11,  1000] loss: 0.907, accuracy: 99.800\n",
      "[11,  1500] loss: 0.915, accuracy: 99.850\n",
      "[11,  2000] loss: 0.912, accuracy: 99.900\n",
      "[11,  2500] loss: 0.917, accuracy: 99.900\n",
      "[11,  3000] loss: 0.917, accuracy: 99.850\n",
      "[11,  3500] loss: 0.893, accuracy: 99.900\n",
      "[11,  4000] loss: 0.918, accuracy: 99.800\n",
      "[11,  4500] loss: 0.913, accuracy: 99.950\n",
      "[11,  5000] loss: 0.915, accuracy: 99.500\n",
      "[11,  5500] loss: 0.912, accuracy: 99.800\n",
      "[11,  6000] loss: 0.912, accuracy: 99.800\n",
      "[11,  6500] loss: 0.909, accuracy: 99.900\n",
      "[11,  7000] loss: 0.915, accuracy: 99.700\n",
      "[11,  7500] loss: 0.911, accuracy: 99.650\n",
      "[11,  8000] loss: 0.923, accuracy: 99.800\n",
      "[11,  8500] loss: 0.908, accuracy: 99.900\n",
      "[11,  9000] loss: 0.918, accuracy: 99.600\n",
      "[11,  9500] loss: 0.914, accuracy: 99.800\n",
      "[11, 10000] loss: 0.923, accuracy: 99.700\n",
      "[11, 10500] loss: 0.913, accuracy: 99.750\n",
      "[11, 11000] loss: 0.911, accuracy: 99.850\n",
      "[11, 11500] loss: 0.899, accuracy: 99.900\n",
      "[11, 12000] loss: 0.911, accuracy: 99.650\n",
      "[11, 12500] loss: 0.924, accuracy: 99.500\n",
      "[11, 13000] loss: 0.909, accuracy: 99.850\n",
      "[11, 13500] loss: 0.909, accuracy: 99.850\n",
      "[11, 14000] loss: 0.925, accuracy: 99.700\n",
      "[11, 14500] loss: 0.908, accuracy: 99.800\n",
      "[11, 15000] loss: 0.899, accuracy: 99.800\n",
      "[12,   500] loss: 0.901, accuracy: 99.900\n",
      "[12,  1000] loss: 0.920, accuracy: 99.900\n",
      "[12,  1500] loss: 0.918, accuracy: 99.700\n",
      "[12,  2000] loss: 0.910, accuracy: 99.700\n",
      "[12,  2500] loss: 0.908, accuracy: 99.800\n",
      "[12,  3000] loss: 0.899, accuracy: 99.950\n",
      "[12,  3500] loss: 0.905, accuracy: 99.800\n",
      "[12,  4000] loss: 0.894, accuracy: 99.850\n",
      "[12,  4500] loss: 0.897, accuracy: 99.750\n",
      "[12,  5000] loss: 0.899, accuracy: 99.950\n",
      "[12,  5500] loss: 0.901, accuracy: 99.850\n",
      "[12,  6000] loss: 0.904, accuracy: 99.650\n",
      "[12,  6500] loss: 0.905, accuracy: 99.850\n",
      "[12,  7000] loss: 0.914, accuracy: 99.750\n",
      "[12,  7500] loss: 0.899, accuracy: 99.850\n",
      "[12,  8000] loss: 0.901, accuracy: 99.650\n",
      "[12,  8500] loss: 0.904, accuracy: 99.650\n",
      "[12,  9000] loss: 0.920, accuracy: 99.550\n",
      "[12,  9500] loss: 0.895, accuracy: 99.900\n",
      "[12, 10000] loss: 0.904, accuracy: 99.900\n",
      "[12, 10500] loss: 0.889, accuracy: 99.850\n",
      "[12, 11000] loss: 0.910, accuracy: 99.850\n",
      "[12, 11500] loss: 0.917, accuracy: 99.550\n",
      "[12, 12000] loss: 0.910, accuracy: 99.750\n",
      "[12, 12500] loss: 0.897, accuracy: 99.900\n",
      "[12, 13000] loss: 0.898, accuracy: 99.700\n",
      "[12, 13500] loss: 0.906, accuracy: 99.600\n",
      "[12, 14000] loss: 0.898, accuracy: 99.800\n",
      "[12, 14500] loss: 0.908, accuracy: 99.700\n",
      "[12, 15000] loss: 0.900, accuracy: 99.650\n",
      "[13,   500] loss: 0.888, accuracy: 99.950\n",
      "[13,  1000] loss: 0.881, accuracy: 99.900\n",
      "[13,  1500] loss: 0.894, accuracy: 99.850\n",
      "[13,  2000] loss: 0.897, accuracy: 99.850\n",
      "[13,  2500] loss: 0.904, accuracy: 99.950\n",
      "[13,  3000] loss: 0.895, accuracy: 99.900\n",
      "[13,  3500] loss: 0.900, accuracy: 99.900\n",
      "[13,  4000] loss: 0.898, accuracy: 99.700\n",
      "[13,  4500] loss: 0.905, accuracy: 99.800\n",
      "[13,  5000] loss: 0.891, accuracy: 99.900\n",
      "[13,  5500] loss: 0.895, accuracy: 99.950\n",
      "[13,  6000] loss: 0.892, accuracy: 99.850\n",
      "[13,  6500] loss: 0.903, accuracy: 99.650\n",
      "[13,  7000] loss: 0.895, accuracy: 99.900\n",
      "[13,  7500] loss: 0.889, accuracy: 99.850\n",
      "[13,  8000] loss: 0.890, accuracy: 99.850\n",
      "[13,  8500] loss: 0.883, accuracy: 100.000\n",
      "[13,  9000] loss: 0.897, accuracy: 99.800\n",
      "[13,  9500] loss: 0.896, accuracy: 99.800\n",
      "[13, 10000] loss: 0.891, accuracy: 99.900\n",
      "[13, 10500] loss: 0.903, accuracy: 99.700\n",
      "[13, 11000] loss: 0.890, accuracy: 99.850\n",
      "[13, 11500] loss: 0.903, accuracy: 99.750\n",
      "[13, 12000] loss: 0.895, accuracy: 99.700\n",
      "[13, 12500] loss: 0.895, accuracy: 99.800\n",
      "[13, 13000] loss: 0.898, accuracy: 99.750\n",
      "[13, 13500] loss: 0.893, accuracy: 99.800\n",
      "[13, 14000] loss: 0.908, accuracy: 99.600\n",
      "[13, 14500] loss: 0.904, accuracy: 99.850\n",
      "[13, 15000] loss: 0.888, accuracy: 99.750\n",
      "[14,   500] loss: 0.894, accuracy: 99.750\n",
      "[14,  1000] loss: 0.887, accuracy: 99.850\n",
      "[14,  1500] loss: 0.880, accuracy: 99.900\n",
      "[14,  2000] loss: 0.887, accuracy: 99.850\n",
      "[14,  2500] loss: 0.890, accuracy: 99.800\n",
      "[14,  3000] loss: 0.890, accuracy: 99.800\n",
      "[14,  3500] loss: 0.883, accuracy: 99.650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,  4000] loss: 0.886, accuracy: 99.950\n",
      "[14,  4500] loss: 0.888, accuracy: 99.950\n",
      "[14,  5000] loss: 0.892, accuracy: 99.950\n",
      "[14,  5500] loss: 0.893, accuracy: 99.700\n",
      "[14,  6000] loss: 0.894, accuracy: 99.900\n",
      "[14,  6500] loss: 0.895, accuracy: 99.900\n",
      "[14,  7000] loss: 0.891, accuracy: 99.950\n",
      "[14,  7500] loss: 0.888, accuracy: 99.900\n",
      "[14,  8000] loss: 0.887, accuracy: 99.900\n",
      "[14,  8500] loss: 0.889, accuracy: 99.800\n",
      "[14,  9000] loss: 0.897, accuracy: 99.750\n",
      "[14,  9500] loss: 0.884, accuracy: 99.900\n",
      "[14, 10000] loss: 0.878, accuracy: 99.900\n",
      "[14, 10500] loss: 0.890, accuracy: 99.800\n",
      "[14, 11000] loss: 0.890, accuracy: 99.950\n",
      "[14, 11500] loss: 0.889, accuracy: 99.650\n",
      "[14, 12000] loss: 0.901, accuracy: 99.600\n",
      "[14, 12500] loss: 0.897, accuracy: 99.900\n",
      "[14, 13000] loss: 0.878, accuracy: 100.000\n",
      "[14, 13500] loss: 0.880, accuracy: 99.950\n",
      "[14, 14000] loss: 0.901, accuracy: 99.600\n",
      "[14, 14500] loss: 0.895, accuracy: 99.700\n",
      "[14, 15000] loss: 0.892, accuracy: 99.600\n",
      "[15,   500] loss: 0.880, accuracy: 99.850\n",
      "[15,  1000] loss: 0.879, accuracy: 99.950\n",
      "[15,  1500] loss: 0.880, accuracy: 99.900\n",
      "[15,  2000] loss: 0.888, accuracy: 99.900\n",
      "[15,  2500] loss: 0.881, accuracy: 99.950\n",
      "[15,  3000] loss: 0.881, accuracy: 99.800\n",
      "[15,  3500] loss: 0.882, accuracy: 100.000\n",
      "[15,  4000] loss: 0.882, accuracy: 99.900\n",
      "[15,  4500] loss: 0.891, accuracy: 99.850\n",
      "[15,  5000] loss: 0.892, accuracy: 99.750\n",
      "[15,  5500] loss: 0.879, accuracy: 99.950\n",
      "[15,  6000] loss: 0.880, accuracy: 99.900\n",
      "[15,  6500] loss: 0.889, accuracy: 99.900\n",
      "[15,  7000] loss: 0.885, accuracy: 99.850\n",
      "[15,  7500] loss: 0.891, accuracy: 99.600\n",
      "[15,  8000] loss: 0.880, accuracy: 99.850\n",
      "[15,  8500] loss: 0.898, accuracy: 99.550\n",
      "[15,  9000] loss: 0.892, accuracy: 99.900\n",
      "[15,  9500] loss: 0.897, accuracy: 99.750\n",
      "[15, 10000] loss: 0.882, accuracy: 99.900\n",
      "[15, 10500] loss: 0.893, accuracy: 99.850\n",
      "[15, 11000] loss: 0.879, accuracy: 99.800\n",
      "[15, 11500] loss: 0.882, accuracy: 99.900\n",
      "[15, 12000] loss: 0.879, accuracy: 99.950\n",
      "[15, 12500] loss: 0.888, accuracy: 99.650\n",
      "[15, 13000] loss: 0.889, accuracy: 99.800\n",
      "[15, 13500] loss: 0.885, accuracy: 99.700\n",
      "[15, 14000] loss: 0.878, accuracy: 99.900\n",
      "[15, 14500] loss: 0.882, accuracy: 99.900\n",
      "[15, 15000] loss: 0.882, accuracy: 99.750\n",
      "[16,   500] loss: 0.877, accuracy: 99.900\n",
      "[16,  1000] loss: 0.892, accuracy: 99.950\n",
      "[16,  1500] loss: 0.873, accuracy: 99.950\n",
      "[16,  2000] loss: 0.885, accuracy: 99.900\n",
      "[16,  2500] loss: 0.880, accuracy: 99.750\n",
      "[16,  3000] loss: 0.894, accuracy: 99.900\n",
      "[16,  3500] loss: 0.888, accuracy: 99.950\n",
      "[16,  4000] loss: 0.877, accuracy: 99.850\n",
      "[16,  4500] loss: 0.884, accuracy: 99.850\n",
      "[16,  5000] loss: 0.871, accuracy: 99.850\n",
      "[16,  5500] loss: 0.862, accuracy: 99.900\n",
      "[16,  6000] loss: 0.876, accuracy: 99.850\n",
      "[16,  6500] loss: 0.887, accuracy: 99.950\n",
      "[16,  7000] loss: 0.876, accuracy: 99.950\n",
      "[16,  7500] loss: 0.874, accuracy: 99.850\n",
      "[16,  8000] loss: 0.888, accuracy: 99.850\n",
      "[16,  8500] loss: 0.874, accuracy: 99.900\n",
      "[16,  9000] loss: 0.891, accuracy: 99.800\n",
      "[16,  9500] loss: 0.883, accuracy: 99.900\n",
      "[16, 10000] loss: 0.876, accuracy: 99.850\n",
      "[16, 10500] loss: 0.887, accuracy: 99.850\n",
      "[16, 11000] loss: 0.891, accuracy: 100.000\n",
      "[16, 11500] loss: 0.893, accuracy: 99.850\n",
      "[16, 12000] loss: 0.873, accuracy: 99.750\n",
      "[16, 12500] loss: 0.880, accuracy: 99.800\n",
      "[16, 13000] loss: 0.879, accuracy: 99.800\n",
      "[16, 13500] loss: 0.891, accuracy: 99.800\n",
      "[16, 14000] loss: 0.882, accuracy: 99.900\n",
      "[16, 14500] loss: 0.862, accuracy: 99.900\n",
      "[16, 15000] loss: 0.873, accuracy: 99.900\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training network over 2 epochs\n",
    "capsule_net = CapsNet()\n",
    "\n",
    "# Optimizer: Adam\n",
    "criterion = CapsuleLoss()\n",
    "optimizer = Adam(capsule_net.parameters(), lr=1e-3)\n",
    "#optimizer = optim.SGD(capsule_net.parameters(), lr=0.001, momentum=0.9)\n",
    "epochs=20\n",
    "capsule_net.train()\n",
    "total = 0\n",
    "correct = 0\n",
    "eye = torch.eye(len(classes))\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    writer = SummaryWriter(logdir='CapsNet_10_MNIST_20epochs/training_epoch%d'%(epoch))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    eye = torch.eye(len(classes))\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, reconstructions = capsule_net(inputs)\n",
    "        labels_eye = eye[labels]\n",
    "        loss = criterion(outputs, labels_eye, inputs, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0) #count the number of labels with right shape\n",
    "        correct += (predicted == labels).sum().item() #count the number of correct prediction\n",
    "        \n",
    "        if i % 500 == 499:    # print every 500 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f, accuracy: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 500, 100*float(correct)/float(total)))\n",
    "            \n",
    "            writer.add_scalar('accuracy_train', 100*float(correct)/float(total), i)\n",
    "            writer.add_scalar('loss_train', running_loss / 500, i)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "    \n",
    "    #added check point\n",
    "    if epoch%2 == 0:\n",
    "        PATH = './checkpoint.1.pth'\n",
    "        torch.save(capsule_net.state_dict(), PATH)\n",
    "        \n",
    "    writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training saving\n",
    "PATH = './MNIST_CapsNet_SGD_20epochs_3.10.pth'\n",
    "torch.save(capsule_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  500] loss: 0.891, accuracy: 98.950\n",
      "[ 1000] loss: 0.911, accuracy: 98.200\n",
      "[ 1500] loss: 0.911, accuracy: 99.300\n",
      "[ 2000] loss: 0.948, accuracy: 99.650\n",
      "[ 2500] loss: 0.936, accuracy: 99.550\n",
      "Accuracy of the network on the 10000 test images: 99 %\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "PATH = './MNIST_CapsNet_SGD_20epochs_3.10.pth'\n",
    "#Load previously net from choosen training\n",
    "capsule_net = CapsNet()\n",
    "capsule_net.load_state_dict(torch.load(PATH))\n",
    "criterion = CapsuleLoss()\n",
    "optimizer = Adam(capsule_net.parameters(), lr=1e-3)\n",
    "capsule_net.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "correct_final = 0\n",
    "total_final = 0\n",
    "eye = torch.eye(len(classes))\n",
    "\n",
    "writer = SummaryWriter(logdir='CapsNet_10_MNIST_20epochs/test.2')\n",
    "for i, datas in enumerate(testloader, 0):\n",
    "    inputs, labels = datas\n",
    "    \n",
    "    target = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "    optimizer.zero_grad()    \n",
    "    output, reconstructions = capsule_net(inputs)\n",
    "    \n",
    "    _,predicted=torch.max(output,1)\n",
    "    labels_eye = eye[labels]\n",
    "    loss = criterion(output, labels_eye, inputs, reconstructions)\n",
    "    test_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    total += labels.size(0) #count the number of labels with right shape\n",
    "    correct += (predicted == labels).sum().item() #count the number of right labels\n",
    "    total_final += labels.size(0) #count the number of labels with right shape\n",
    "    correct_final += (predicted == labels).sum().item() #count the number of right labels \n",
    "    if i % 500 == 499:    # print every 500 mini-batches\n",
    "        print('[%5d] loss: %.3f, accuracy: %.3f' %( i + 1, (test_loss / 500), (100*correct/total) ))\n",
    "        \n",
    "        writer.add_scalar('accuracy_test', 100*correct/total, i)\n",
    "        writer.add_scalar('loss_test', test_loss / 500, i)\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0    \n",
    "writer.close()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct_final / total_final))    \n",
    "    \n",
    "print (test_loss / len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(logdir='CapsNet_10_MNIST/graph')\n",
    "writer.add_graph(capsule_net, inputs)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
